{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CSE 572: Lab 6\n",
    "\n",
    "In this lab, you will practice implementing the probabilistic Naive Bayes classifier.\n",
    "\n",
    "To execute and make changes to this notebook, click File > Save a copy to save your own version in your Google Drive or Github. Read the step-by-step instructions below carefully. To execute the code, click on each cell below and press the SHIFT-ENTER keys simultaneously or by clicking the Play button. \n",
    "\n",
    "When you finish executing all code/exercises, save your notebook then download a copy (.ipynb file). Submit the following **three** things:\n",
    "1. a link to your Colab notebook,\n",
    "2. the .ipynb file, and\n",
    "3. a pdf of the executed notebook on Canvas.\n",
    "\n",
    "To generate a pdf of the notebook, click File > Print > Save as PDF.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implement Naive Bayes manually"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You like to play pickup soccer at the Sun Devil Fitness Center (SDFC). However, you noticed that on some days there are enough people to play a scrimmage but on some days there are not enough people. It's more fun for you to play a scrimmage, and it's a lot of effort for you to pull yourself away from studying Data Mining, so you decide that you only want to go to the SDFC to play soccer when it's likely there will be enough players for a scrimmage. You think players' attendance might be dependent on the weather and proximity to exam weeks, so you collect some observations about these attributes on the days that you've gone to play in the past and whether or not there was a scrimmage on those days. You code that dataset below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Create the dataframe\n",
    "d = {\n",
    "     'weather': ['Sunny','Sunny','Overcast','Rainy','Rainy','Rainy','Overcast','Sunny','Sunny','Rainy','Sunny','Overcast','Overcast','Rainy'],\n",
    "     'exam-proximity': ['High','High','High','Medium','Low','Low','Low','Medium','Low','Medium','Medium','Medium','High','Medium'],\n",
    "     'scrimmage': ['No','No','Yes','Yes','Yes','No','Yes','No','Yes','Yes','Yes','Yes','Yes','No']\n",
    "    }\n",
    "\n",
    "df = pd.DataFrame(data=d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Today, the weather is Sunny and the proximity to exams is Medium. Implement a Naive Bayes classifier to decide if there is likely to be a scrimmage today and thus you should go to the SDFC.\n",
    "\n",
    "First, calculate the prior probability of a scrimmage $P(Y=yes)$ and $P(Y=no)$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p_y_yes = df[df['scrimmage'] == 'Yes'].shape[0] / df.shape[0]\n",
    "\n",
    "p_y_yes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "\n",
    "p_y_no"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we calculate the class-conditional probabilities for the weather and exam-proximity attributes: $P(weather=sunny | no)$, $P(weather=sunny | yes)$, $P(examproximity=medium | no)$, $P(examproximity=medium | yes)$. \n",
    "\n",
    "Recall that for categorical attributes, $P(X_i = c | y) = \\frac{n_c}{n}$ where $n_c$ is number of instances where $X_i = c$ and belongs to class $y$ and $n$ is total number of occurrences of class y."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p_sunny_no = df[(df['scrimmage'] == 'No') & (df['weather']=='Sunny')].shape[0] / df[df['scrimmage'] == 'No'].shape[0]\n",
    "\n",
    "p_sunny_no"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "\n",
    "p_sunny_yes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p_medium_no = df[(df['scrimmage'] == 'No') & (df['exam-proximity']=='Medium')].shape[0] / df[df['scrimmage'] == 'No'].shape[0]\n",
    "\n",
    "p_medium_no"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "\n",
    "p_medium_yes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 1:**\n",
    "\n",
    "The Naive Bayes assumption is that weather ($X_1$) and exam proximity ($X_2$) are conditionally independent given the class value $Y$. This is true if $P(X_1 | X_2, Y) = P(X_1 | Y)$, i.e., the value of $X_2$ has no influence on the value of $X_1$ given $Y$. Thus the Naive Bayes assumption is that weather and exam proximity are independent given the variable $Y$ (whether or not there is a scrimmage). Is this a reasonable assumption? Why or why not?\n",
    "\n",
    "**Answer:**\n",
    "\n",
    "YOUR ANSWER HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Assuming the attributes are conditionally independent given $Y$ allows us to compute $P(X|Y)$ by multiplying the class-conditional probabilities $P(X_1|Y)$ and $P(X_2|Y)$. We compute this below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p_x_yes = p_sunny_yes * p_medium_yes\n",
    "\n",
    "p_x_yes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "\n",
    "p_x_no"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we are ready to determine our classification. According to Bayes theorem, if $P(X|No)P(No) > P(X|Yes)P(Yes)$, then $P(No|X) > P(Yes|X)$ and we should classify Scrimmage = No and we should not go to the SDFC. If the reverse is true, then we should classify Scrimmage = Yes and we should go to the SDFC. \n",
    "\n",
    "Below, we calculate $P(X|No)P(No) > $  and $P(X|Yes)P(Yes)$ and check if $P(X|No)P(No) > P(X|Yes)P(Yes)$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p_no_x = p_x_no * p_y_no\n",
    "\n",
    "p_no_x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#YOUR CODE HERE\n",
    "\n",
    "p_yes_x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if P(Y=no|X) is greater than P(Y=yes|X)\n",
    "p_no_x > p_yes_x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 2:**\n",
    "\n",
    "Is it likely there will be a scrimmage today, and thus should you go to the SDFC to play soccer? Answer Yes or No.\n",
    "\n",
    "**Answer:**\n",
    "\n",
    "YOUR ANSWER HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implement Naive Bayes using Scikit-learn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this section, we will use scikit-learn to implement Gaussian Naive Bayes to predict whether samples in the Wisconsin breast cancer dataset have the class value 'benign' or 'malignant'. Gaussian Naive Bayes estimates the class-conditional probabilities for each attribute by estimating a Gaussian probability density function for each attribute. You can read more about the Gaussian Naive Bayes classifier (and other Naive Bayes classifiers assuming different types of probability distributions) in the [sklearn documentation](https://scikit-learn.org/stable/modules/naive_bayes.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Load the Wisconsin breast cancer dataset\n",
    "data = pd.read_csv('https://archive.ics.uci.edu/ml/machine-learning-databases/breast-cancer-wisconsin/breast-cancer-wisconsin.data', header=None)\n",
    "data.columns = ['Sample code', 'Clump Thickness', 'Uniformity of Cell Size', 'Uniformity of Cell Shape',\n",
    "                'Marginal Adhesion', 'Single Epithelial Cell Size', 'Bare Nuclei', 'Bland Chromatin',\n",
    "                'Normal Nucleoli', 'Mitoses','Class']\n",
    "\n",
    "data = data.drop(['Sample code'],axis=1)\n",
    "\n",
    "data = data.replace('?',np.NaN)\n",
    "data['Bare Nuclei'] = pd.to_numeric(data['Bare Nuclei'])\n",
    "\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After loading the dataset, we clean it by removing samples with missing data, duplicates, or outliers using the code from Lab 2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def inds_nans(df):\n",
    "    inds = df.isna().any(axis=1)\n",
    "    # print('Found {} rows that had NaN values.'.format(inds.sum()))\n",
    "    return inds\n",
    "\n",
    "def inds_dups(df):\n",
    "    inds = df.duplicated()\n",
    "    # print('Found {} rows that were duplicates.'.format(inds.sum()))\n",
    "    return inds\n",
    "\n",
    "def inds_outliers(df):\n",
    "    # In this example, we defined outliers as values that are +/- 3 standard deviations \n",
    "    # from the mean value. To identify such values, we need to compute the Z score for \n",
    "    # every value by subtracting the feature-wise mean and dividing by the feature-wise \n",
    "    # standard deviation (also known as standardizing the data).\n",
    "    df = df[df.columns[:-1]]\n",
    "    Z = (df-df.mean())/df.std()\n",
    "    # The below code will give a value of True or False for each row. The row will be\n",
    "    # True if all of the feature values for that row were within 3 standard deviations of \n",
    "    # the mean. The row will be False if at leaset one of the feature values for that row\n",
    "    # was NOT within 3 standard deviations of the mean.\n",
    "    inlier_inds = ((Z > -3).sum(axis=1)==9) & ((Z <= 3).sum(axis=1)==9)\n",
    "    # The outliers are the inverse boolean values of the above\n",
    "    outlier_inds = ~inlier_inds\n",
    "    # print('Found {} rows that were outliers.'.format(outlier_inds.sum()))\n",
    "    return outlier_inds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select only the rows at index locations that were not nans, duplicates, or outliers\n",
    "data_clean = data.loc[~((inds_nans(data) | inds_dups(data)) | inds_outliers(data)),:]\n",
    "\n",
    "data_clean"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we normalize the data using the code from Lab 3 so the features will have approximately normal distributions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import preprocessing\n",
    "\n",
    "# Normalize the feature columns\n",
    "data_clean[data_clean.columns[:-1]] = preprocessing.normalize(data_clean[data_clean.columns[:-1]], norm='l2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_clean"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Split the data into a training and test set with 70% train and 30% test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(data_clean[data_clean.columns[:-1]], \n",
    "                                                    data_clean[data_clean.columns[-1]], \n",
    "                                                    test_size=0.3, \n",
    "                                                    random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use the GaussianNB object in sklearn to fit a Gaussian Naive Bayes classifier and predict the class labels for the test set based on probabilities estimated from the training set. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "gnb = GaussianNB()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit the model parameters using the training data\n",
    "gnb = gnb.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict the test set classes using the trained model\n",
    "y_pred = gnb.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compute the accuracy of this model on the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compute the accuracy of this model on the training set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE HERE"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
