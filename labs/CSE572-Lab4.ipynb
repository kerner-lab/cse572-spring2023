{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CSE 572: Lab 4\n",
    "\n",
    "In this lab, you will practice implementing k nearest neighbors for classification.\n",
    "\n",
    "To execute and make changes to this notebook, click File > Save a copy to save your own version in your Google Drive or Github. Read the step-by-step instructions below carefully. To execute the code, click on each cell below and press the SHIFT-ENTER keys simultaneously or by clicking the Play button. \n",
    "\n",
    "When you finish executing all code/exercises, save your notebook then download a copy (.ipynb file). Submit the following **three** things:\n",
    "1. a link to your Colab notebook,\n",
    "2. the .ipynb file, and\n",
    "3. a pdf of the executed notebook on Canvas.\n",
    "\n",
    "To generate a pdf of the notebook, click File > Print > Save as PDF.\n",
    "\n",
    "Acknowledgment: Much of the content in this notebook was adapted from Introduction to Data Mining, 2nd Edition by Tan, Steinbach, Karpatne, Kumar."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset preparation\n",
    "\n",
    "We will use the Wisconsin Breast Cancer Dataset for this exercise. We used the original version of the dataset for Lab 3 (found [here](https://archive.ics.uci.edu/ml/datasets/breast+cancer+wisconsin+(original)), but for Lab 4 we will use a newer version of the dataset with different features. This dataset does not have any missing attribute values, so we ill skip cleaning it.\n",
    "\n",
    "Read about this dataset here: https://archive.ics.uci.edu/ml/datasets/Breast+Cancer+Wisconsin+%28Diagnostic%29\n",
    "\n",
    "Description of dataset from UCI documentation: \n",
    "\n",
    "Number of instances: 569 \n",
    "\n",
    "Number of attributes: 32 (ID, diagnosis, 30 real-valued input features)\n",
    "\n",
    "Attribute information\n",
    "\n",
    "Features are computed from a digitized image of a fine needle aspirate (FNA) of a breast mass.  They describe characteristics of the cell nuclei present in the image. \n",
    "\n",
    "1. ID number\n",
    "2. Diagnosis (M = malignant, B = benign)\n",
    "3. Attributes 3-32:\n",
    "\n",
    "Ten real-valued features are computed for each cell nucleus:\n",
    "\n",
    "\ta) radius (mean of distances from center to points on the perimeter)\n",
    "\tb) texture (standard deviation of gray-scale values)\n",
    "\tc) perimeter\n",
    "\td) area\n",
    "\te) smoothness (local variation in radius lengths)\n",
    "\tf) compactness (perimeter^2 / area - 1.0)\n",
    "\tg) concavity (severity of concave portions of the contour)\n",
    "\th) concave points (number of concave portions of the contour)\n",
    "\ti) symmetry \n",
    "\tj) fractal dimension (\"coastline approximation\" - 1)\n",
    "\n",
    "The mean, standard error, and \"worst\" or largest (mean of the three\n",
    "largest values) of these features were computed for each image,\n",
    "resulting in 30 features.  For instance, attribute 3 is Mean Radius, attribute 13\n",
    "13 is Radius standard error, attribute 23 is Worst Radius."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the original dataset\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "data = pd.read_csv('https://archive.ics.uci.edu/ml/machine-learning-databases/breast-cancer-wisconsin/wdbc.data', header=None)\n",
    "\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop the first column which represents the ID number\n",
    "data = data.drop(columns=0)\n",
    "\n",
    "# Rename column 1 to \"class\" since this column represents the class (M=malignant, B=benign)\n",
    "data = data.rename(columns={1: \"class\"})\n",
    "\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset splits\n",
    "\n",
    "It is common practice in data mining and machine learning to split a dataset into training, validation, and test sets. \n",
    "\n",
    "- Training set: subset of dataset used for training/fitting model parameters\n",
    "- Validation set: subset of dataset used to evaluate model generalization performance and tune hyperparameters (model choices)\n",
    "- Test set: subset of dataset used to test performance after initial vetting using validation set\n",
    "\n",
    "The training set is usually allocated the largest percentage of the total dataset. For example, a common split might be 60/20/20\\% or 80/10/10\\% of the data assigned to training/validation/test subsets respectively. \n",
    "\n",
    "This example shows how to split the dataset into training, validation, and test subsets using a simple random sampling strategy (without replacement). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the random seed\n",
    "SEED = 42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sample 60% of the instances for the training set\n",
    "train = data.sample(frac=0.6, random_state=SEED)\n",
    "train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sample 20% for the validation set. \n",
    "# First we need to drop the training instances from our dataframe to sample from the remaining instances.\n",
    "data_remaining = data.drop(train.index)\n",
    "# Note that since we are sampling from the rows remaining after removing the training subset, which \n",
    "# leaves 40% of the total data, we need to sample 50% of the remaining dataset to result in 20% of \n",
    "# the original dataset.\n",
    "val = data_remaining.sample(frac=0.5, random_state=SEED)\n",
    "val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop the validation instances from data_remaining\n",
    "# This leaves us with the remaining 20% of the original dataset, \n",
    "# which makes up our test set.\n",
    "test = data_remaining.drop(val.index)\n",
    "test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use `value_counts()` to get the number of benign vs. malevolent examples in each subset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### K-Nearest neighbors classifier\n",
    "\n",
    "In this approach, the class label of a test instance is predicted based on the majority class of its *k* closest training instances. The number of nearest neighbors, *k*, is a hyperparameter that must be provided by the user, along with the distance metric. By default, we can use Euclidean distance (which is equivalent to Minkowski distance with an exponent factor equals to p=2):\n",
    "\n",
    "\\begin{equation*}\n",
    "\\textrm{Minkowski distance}(x,y) = \\bigg[\\sum_{i=1}^N |x_i-y_i|^p \\bigg]^{\\frac{1}{p}}\n",
    "\\end{equation*}\n",
    "\n",
    "We will use the Scikit-learn library to implement the KNN classifier. In `sklearn`, classifier objects have a `fit()` function used to train the classifier model. This function expects two arguments: `X` (the input features, formatted as a matrix in which the rows are individual training samples and the columns are the features) and `y` (the target class to predict, formatted as a vector in which the rows are individual training samples and the column is the class label). You can read more about the `sklearn` API [here](https://scikit-learn.org/stable/developers/develop.html#apis-of-scikit-learn-objects).\n",
    "\n",
    "In the code block below, write code to create new variables for X and y (for the train, val, and test sets) that we can pass to our classifier functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = # YOUR CODE HERE\n",
    "X_val = # YOUR CODE HERE\n",
    "X_test = # YOUR CODE HERE\n",
    "\n",
    "y_train = # YOUR CODE HERE\n",
    "y_val = # YOUR CODE HERE\n",
    "y_test = # YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standardize the data using the StandardScaler.\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler = StandardScaler().fit(X_train)\n",
    "X_train = scaler.transform(X_train)\n",
    "X_val = scaler.transform(X_val)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 1: How does StandardScaler scale the data?**\n",
    "\n",
    "**Answer:**\n",
    "\n",
    "YOUR ANSWER HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 2: Why would we use the training set to calculate the scaling parameters? Why not use the entire dataset (before splitting) instead?**\n",
    "\n",
    "**Answer:**\n",
    "\n",
    "YOUR ANSWER HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the code below, we'll implement the KNN classifier using different settings of the hyperparameter $k$ or `n_neighbors` (number of neighbors) and observe how the training and validation accuracy changes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "numNeighbors = range(1, 31)\n",
    "trainAcc = []\n",
    "valAcc = []\n",
    "\n",
    "for k in numNeighbors:\n",
    "    clf = KNeighborsClassifier(n_neighbors=k, metric='minkowski', p=2)\n",
    "    clf.fit(X=X_train, y=y_train)\n",
    "    Y_predTrain = clf.predict(X_train)\n",
    "    Y_predVal = clf.predict(X_val)\n",
    "    trainAcc.append(accuracy_score(y_train, Y_predTrain))\n",
    "    valAcc.append(accuracy_score(y_val, Y_predVal))\n",
    "\n",
    "plt.plot(numNeighbors, trainAcc, 'ro-', numNeighbors, valAcc,'bv--')\n",
    "plt.legend(['Training Accuracy','Validation Accuracy'])\n",
    "plt.xlabel('Number of neighbors')\n",
    "plt.ylabel('Accuracy')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In class, we discussed other distance metrics that could be used besides Euclidean distance, such as absolute distance (Minkowski distance with order = 1) and cosine distance. Implement kNN and create the same plot as above, but using 1) absolute distance and 2) cosine distance. You will need to consult the [scikit-learn documentation](https://scikit-learn.org/stable/modules/generated/sklearn.neighbors.KNeighborsClassifier.html) to find how to change the distance metric."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Absolute distance ###\n",
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Cosine distance ###\n",
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 3: Which distance metric(s) gave the best overall accuracy on the validation set? You can refer to the highest validation accuracy achieved by each distance metric for this question.**\n",
    "\n",
    "**Answer:**\n",
    "\n",
    "YOUR ANSWER HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Weighted kNN\n",
    "By default, kNN classifier in sklearn uses uniform weights---i.e., each neighbor is weighted equally when determining the class label based on the k nearest neighbors. Alternatively, we could weight the decision based on the distance of each neighbor from the test instance. Consult the documentation to figure out how to weight neighbors by their distance during prediction, then implement weighted kNN and generate the same plot as in the previous cells. Use absolute distance as the distance metric."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Weighted kNN ###\n",
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To compute our final test accuracy, we'll choose a distance metric and number of neighbors that gave good performance on the validation set. Below, train a kNN model using Absolute Distance (L1 distance) and 3 neighbors (with uniform weights), then compute the test accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE HERE"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
