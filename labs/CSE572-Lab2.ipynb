{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CSE 572: Lab 2\n",
    "\n",
    "This lab contains a Data Exploration module and a practice exercise in which you will use some of the operations from the Data Exploration module.\n",
    "\n",
    "To execute and make changes to this notebook, click File > Save a copy to save your own version in your Google Drive or Github. Read the step-by-step instructions below carefully. To execute the code, click on each cell below and press the SHIFT-ENTER keys simultaneously or by clicking the Play button. \n",
    "\n",
    "When you finish executing all code/exercises, save your notebook then download a copy (.ipynb file). Submit 1) a link to your Colab notebook, 2) the .ipynb file, and **3) a pdf of the executed notebook** on Canvas.\n",
    "\n",
    "To generate a pdf of the notebook, click File > Print > Save as PDF."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Exploration\n",
    "\n",
    "The following tutorial contains examples of Python code for data exploration. You should refer to the \"Data Exploration\" chapter of the \"Introduction to Data Mining\" book (available at https://www-users.cs.umn.edu/~kumar001/dmbook/index.php) to understand some of the concepts introduced in this tutorial notebook.\n",
    "\n",
    "Data exploration refers to the preliminary investigation of data in order\n",
    "to better understand its specific characteristics. There are two key motivations for data exploration:\n",
    "1. To help users select the appropriate preprocessing and data analysis techniques to be used.\n",
    "2. To make use of humansâ€™ abilities to recognize patterns in the data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Summary Statistics\n",
    "\n",
    "Summary statistics are quantities, such as the mean and standard deviation, that capture various characteristics of a potentially large set of values with a single number or a small set of numbers. In this tutorial, we will use the Iris sample data, which contains information on 150 Iris flowers, 50 each from one of three Iris species: Setosa, Versicolour, and Virginica. Each flower is characterized by five attributes:\n",
    "\n",
    "- sepal length in centimeters\n",
    "\n",
    "- sepal width in centimeters\n",
    "\n",
    "- petal length in centimeters\n",
    "\n",
    "- petal width in centimeters\n",
    "\n",
    "- class (Setosa, Versicolour, Virginica) \n",
    "\n",
    "In this tutorial, you will learn how to:\n",
    "\n",
    "- Load a CSV data file into a Pandas DataFrame object.\n",
    "\n",
    "- Compute various summary statistics from the DataFrame."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1.** First, you need to download the <a href=\"http://archive.ics.uci.edu/ml/datasets/Iris\">Iris dataset</a> from the UCI machine learning repository.\n",
    "\n",
    "**<font color='red'>Code:</font>** The following code uses Pandas to read the CSV file and store them in a DataFrame object named data. Next, it will display the first five rows of the data frame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "data = pd.read_csv('http://archive.ics.uci.edu/ml/machine-learning-databases/iris/iris.data',header=None)\n",
    "data.columns = ['sepal length', 'sepal width', 'petal length', 'petal width', 'class']\n",
    "\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How big is this dataset? Print the number of samples/records and attributes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('There are {} samples and {} attributes in this dataset.'.format(data.shape[0], data.shape[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2.** For each quantitative attribute, calculate its average, standard deviation, minimum, and maximum values.\n",
    "\n",
    "**<font color=\"red\">Code:</font>**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pandas.api.types import is_numeric_dtype\n",
    "\n",
    "for col in data.columns:\n",
    "    if is_numeric_dtype(data[col]):\n",
    "        print('%s:' % (col))\n",
    "        print('\\t Mean = %.2f' % data[col].mean())\n",
    "        print('\\t Standard deviation = %.2f' % data[col].std())\n",
    "        print('\\t Minimum = %.2f' % data[col].min())\n",
    "        print('\\t Maximum = %.2f' % data[col].max())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**3.** For the qualitative attribute (class), count the frequency for each of its distinct values.\n",
    "\n",
    "**<font color=\"red\">Code:</font>**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['class'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**4.** It is also possible to display the summary for all the attributes simultaneously in a table using the describe() function. If an attribute is quantitative, it will display its mean, standard deviation and various quantiles (including minimum, median, and maximum) values. If an attribute is qualitative, it will display its number of unique values and the top (most frequent) values. \n",
    "\n",
    "**<font color=\"red\">Code:</font>**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.describe(include='all')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that count refers to the number of non-missing values for each attribute."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**5.** For multivariate statistics, you can compute the covariance and correlation between pairs of attributes.\n",
    "\n",
    "**<font color=\"red\">Code:</font>**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Covariance:')\n",
    "data.cov()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Correlation:')\n",
    "data.corr()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 1: Which two features have the strongest correlation? (ignore the diagonals, which show each feature's correlation with itself)**\n",
    "\n",
    "\n",
    "**Answer:**\n",
    "\n",
    "YOUR ANSWER HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Data Visualization\n",
    "\n",
    "Data visualization is the display of information in a graphic or tabular format. Successful visualization requires that the data (information) be converted into a visual format so that the characteristics of the data and the relationships\n",
    "among data items or attributes can be analyzed or reported.\n",
    "\n",
    "In this tutorial, you will learn how to display the Iris data created in Section 3.1. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1.** First, we will display the histogram for the sepal length attribute by discretizing it into 8 separate bins and counting the frequency for each bin.\n",
    "\n",
    "**<font color=\"red\">Code:</font>**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "data['sepal length'].hist(bins=8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot a histogram of each of the features in a single plot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "fig, axes = plt.subplots(nrows=2, ncols=2)\n",
    "\n",
    "for i, col in enumerate(data.columns[:4]):\n",
    "    data[col].hist(bins=8, ax=axes.flat[i])\n",
    "    axes.flat[i].set_title(col)\n",
    "    if 'length' in col:\n",
    "        axes.flat[i].set_xlabel('length (cm)')\n",
    "    elif 'width' in col:\n",
    "        axes.flat[i].set_xlabel('width (cm)')\n",
    "    axes.flat[i].set_ylabel('counts')\n",
    "\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 2: What do these histograms tells us about the distribution of the values of each feature in our dataset? Are they uniformly distributed, Gaussian-distributed, or other? Do they appear to have one mode, or multiple? Describe the distribution of each of the features.**\n",
    "\n",
    "**Answer:**\n",
    "\n",
    "YOUR ANSWER HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2.** A boxplot can also be used to show the distribution of values for each attribute.\n",
    "\n",
    "**<font color=\"red\">Code:</font>**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.boxplot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**3.** For each pair of attributes, we can use a scatter plot to visualize their joint distribution.\n",
    "\n",
    "**<font color=\"red\">Code:</font>**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fig, axes = plt.subplots(3, 2, figsize=(12,12))\n",
    "index = 0\n",
    "for i in range(3):\n",
    "    for j in range(i+1,4):\n",
    "        ax1 = int(index/2)\n",
    "        ax2 = index % 2\n",
    "        axes[ax1][ax2].scatter(data[data.columns[i]], data[data.columns[j]], color='red')\n",
    "        axes[ax1][ax2].set_xlabel(data.columns[i])\n",
    "        axes[ax1][ax2].set_ylabel(data.columns[j])\n",
    "        index = index + 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**4.** If we color the scatter plot points by the class value for each sample, we can see if the classes are clustered in any of the attribute pairs.\n",
    "\n",
    "**<font color=\"red\">Code:</font>**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(3, 2, figsize=(12,12))\n",
    "index = 0\n",
    "for i in range(3):\n",
    "    for j in range(i+1,4):\n",
    "        ax1 = int(index/2)\n",
    "        ax2 = index % 2\n",
    "        for iris in data['class'].unique():\n",
    "            axes[ax1][ax2].scatter(data[data['class'] == iris][data.columns[i]], \n",
    "                                   data[data['class'] == iris][data.columns[j]],\n",
    "                                   label=iris,\n",
    "                                   alpha=0.6)\n",
    "        axes[ax1][ax2].set_xlabel(data.columns[i])\n",
    "        axes[ax1][ax2].set_ylabel(data.columns[j])\n",
    "        axes[ax1][ax2].legend(loc='lower right')\n",
    "        index = index + 1\n",
    "        \n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**5.** To see which features are the best and weakest predictors of the iris class, we can visualize the feature value and class value as a scatter plot.\n",
    "\n",
    "**<font color=\"red\">Code:</font>**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(2, 2, figsize=(12,12))\n",
    "index = 0\n",
    "for col_name in data.columns[:-1]:\n",
    "        ax1 = int(index/2)\n",
    "        ax2 = index % 2\n",
    "        axes[ax1][ax2].scatter(data[col_name], data['class'], color='purple')\n",
    "        axes[ax1][ax2].set_xlabel(col_name)\n",
    "        axes[ax1][ax2].set_ylabel('class')\n",
    "        index = index + 1\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 3: Study these plots and review your responses to Questions 1 and 2. Which features are the best predictors of the iris class? The weakest predictors? Which combination of two features separates the classes best?**\n",
    "\n",
    "**Answer:**\n",
    "\n",
    "YOUR ANSWER HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**4.** Parallel coordinates can be used to display all the data points simultaneously. Parallel coordinates have one coordinate axis for each attribute, but the different axes are parallel to one other instead of perpendicular, as is traditional. Furthermore, an object is represented as a line instead of as a point. In the example below, the distribution of values for each class can be identified in a separate color.\n",
    "\n",
    "**<font color=\"red\">Code:</font>**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from pandas.plotting import parallel_coordinates\n",
    "%matplotlib inline\n",
    "\n",
    "parallel_coordinates(data, 'class')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 4: Which of the classes are more similar to each other in terms of their attribute distributions (i.e., their lines overlap most)? If you had to come up with a set of rules for distinguishing between iris-setosa, iris-versicolor, and iris-virginica based on their attribute values, what are some rules you might propose?**\n",
    "\n",
    "**Answer:**\n",
    "\n",
    "YOUR ANSWER HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Data Quality Issues\n",
    "\n",
    "Poor data quality can have an adverse effect on data mining. Among the common data quality issues include noise, outliers, missing values, and duplicate data. This section presents examples of Python code to alleviate some of these data quality problems. We begin with an example dataset from the UCI machine learning repository containing information about breast cancer patients. We will first download the dataset using Pandas read_csv() function and display its first 5 data points.\n",
    "\n",
    "**<font color=\"red\">Code:</font>**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 5: View the documentation for the Wisconsin Breast Cancer dataset [here](https://archive.ics.uci.edu/ml/datasets/Breast+Cancer+Wisconsin+%28Original%29). Who collected this dataset? When did they collect it?**\n",
    "\n",
    "**Answer:**\n",
    "\n",
    "YOUR ANSWER HERE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('https://archive.ics.uci.edu/ml/machine-learning-databases/breast-cancer-wisconsin/breast-cancer-wisconsin.data', header=None)\n",
    "data.columns = ['Sample code', 'Clump Thickness', 'Uniformity of Cell Size', 'Uniformity of Cell Shape',\n",
    "                'Marginal Adhesion', 'Single Epithelial Cell Size', 'Bare Nuclei', 'Bland Chromatin',\n",
    "                'Normal Nucleoli', 'Mitoses','Class']\n",
    "\n",
    "data = data.drop(['Sample code'],axis=1)\n",
    "print('Number of instances = %d' % (YOUR CODE HERE))\n",
    "print('Number of attributes = %d' % (YOUR CODE HERE))\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Print the value counts for the Class attribute."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 6: What does a Class value of 2 indicate? What does 4 indicate?**\n",
    "\n",
    "**Answer:**\n",
    "\n",
    "YOUR ANSWER HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1.1 Missing Values\n",
    "\n",
    "It is not unusual for an object to be missing one or more attribute values. In some cases, the information was not collected; while in other cases, some attributes are inapplicable to the data instances. This section presents examples on the different approaches for handling missing values. \n",
    "\n",
    "According to the description of the data (https://archive.ics.uci.edu/ml/datasets/breast+cancer+wisconsin+(original), the missing values are encoded as '?' in the original data. Our first task is to convert the missing values to NaNs. We can then count the number of missing values in each column of the data.\n",
    "\n",
    "**<font color=\"red\">Code:</font>**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "data = data.replace('?',np.NaN)\n",
    "\n",
    "print('Number of instances = %d' % (data.shape[0]))\n",
    "print('Number of attributes = %d' % (data.shape[1]))\n",
    "\n",
    "print('Number of missing values:')\n",
    "for col in data.columns:\n",
    "    print('\\t%s: %d' % (col,data[col].isna().sum()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Observe that only the 'Bare Nuclei' column contains missing values. In the following example, the missing values in the 'Bare Nuclei' column are replaced by the median value of that column. The values before and after replacement are shown for a subset of the data points.\n",
    "\n",
    "**<font color=\"red\">Code:</font>**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data2 = data['Bare Nuclei']\n",
    "\n",
    "print('Before replacing missing values:')\n",
    "print(data2[20:25])\n",
    "data2 = data2.fillna(data2.median())\n",
    "\n",
    "print('\\nAfter replacing missing values:')\n",
    "print(data2[20:25])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Instead of replacing the missing values, another common approach is to discard the data points that contain missing values. This can be easily accomplished by applying the dropna() function to the data frame.\n",
    "\n",
    "**<font color=\"red\">Code:</font>**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Number of rows in original data = %d' % (data.shape[0]))\n",
    "\n",
    "data2 = data.dropna()\n",
    "print('Number of rows after discarding missing values = %d' % (data2.shape[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1.2 Outliers\n",
    "\n",
    "Outliers are data instances with characteristics that are considerably different from the rest of the dataset. In the example code below, we will draw a boxplot to identify the columns in the table that contain outliers. Note that the values in all columns (except for 'Bare Nuclei') are originally stored as 'int64' whereas the values in the 'Bare Nuclei' column are stored as string objects (since the column initially contains strings such as '?' for representing missing values). Thus, we must  convert the column into numeric values first before creating the boxplot. Otherwise, the column will not be displayed when drawing the boxplot.\n",
    "\n",
    "**<font color=\"red\">Code:</font>**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "data2 = data.drop(['Class'],axis=1)\n",
    "data2['Bare Nuclei'] = pd.to_numeric(data2['Bare Nuclei'])\n",
    "data2.boxplot(figsize=(20,3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The boxplots suggest that only 5 of the columns (Marginal Adhesion, Single Epithetial Cell Size, Bland Cromatin, Normal Nucleoli, and Mitoses) contain abnormally high values. To discard the outliers, we can compute the Z-score for each attribute and remove those instances containing attributes with abnormally high or low Z-score (e.g., if Z > 3 or Z <= -3). \n",
    "\n",
    "**<font color=\"red\">Code:</font>**\n",
    "\n",
    "The following code shows the results of standardizing the columns of the data. To standardize variables, you calculate the mean and standard deviation for a variable. Then, for each observed value of the variable, you subtract the mean and divide by the standard deviation. This results in standard scores that represent the number of standard deviations above or below the mean that a specific observation falls. For instance, a standardized value of 2 indicates that the observation falls 2 standard deviations above the mean.\n",
    "\n",
    "Note that missing values (NaN) are not affected by the standardization process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Z = (data2-data2.mean())/data2.std()\n",
    "Z[20:25]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**<font color=\"red\">Code:</font>**\n",
    "\n",
    "The following code shows the results of discarding columns with Z > 3 or Z <= -3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Number of rows before discarding outliers = %d' % (Z.shape[0]))\n",
    "\n",
    "Z2 = Z.loc[((Z > -3).sum(axis=1)==9) & ((Z <= 3).sum(axis=1)==9),:]\n",
    "print('Number of rows after discarding outliers = %d' % (Z2.shape[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1.3 Duplicate Data\n",
    "\n",
    "Some datasets, especially those obtained by merging multiple data sources, may contain duplicates or near duplicate instances. The term deduplication is often used to refer to the process of dealing with duplicate data issues. \n",
    "\n",
    "**<font color=\"red\">Code:</font>**\n",
    "\n",
    "In the following example, we first check for duplicate instances in the breast cancer dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dups = data.duplicated()\n",
    "print('Number of duplicate rows = %d' % (dups.sum()))\n",
    "data[dups]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The duplicated() function will return a Boolean array that indicates whether each row is a duplicate of a previous row in the table:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dups"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Although such duplicate rows may correspond to samples for different individuals, in this hypothetical example, we assume that the duplicates are samples taken from the same individual and illustrate below how to remove the duplicated rows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Number of rows before discarding duplicates = %d' % (data.shape[0]))\n",
    "data2 = data.drop_duplicates()\n",
    "print('Number of rows after discarding duplicates = %d' % (data2.shape[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, combine all of these pre-processing steps to clean the dataset by 1) dropping the rows that have NaN values, 2) removing outliers with Z score Z > 3 or Z <= -3, and 3) dropping the duplicate rows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 7: How many rows/samples are left after applying all three steps?**\n",
    "\n",
    "**Answer:**\n",
    "\n",
    "YOUR ANSWER HERE"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
