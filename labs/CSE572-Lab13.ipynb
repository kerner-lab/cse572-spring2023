{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CSE 572: Lab 13\n",
    "\n",
    "In this lab, you will practice implementing techniques for dimensionality reduction using Kernel PCA and autoencoder neural networks.\n",
    "\n",
    "To execute and make changes to this notebook, click File > Save a copy to save your own version in your Google Drive or Github. Read the step-by-step instructions below carefully. To execute the code, click on each cell below and press the SHIFT-ENTER keys simultaneously or by clicking the Play button. \n",
    "\n",
    "When you finish executing all code/exercises, save your notebook then download a copy (.ipynb file). Submit the following **three** things:\n",
    "1. a link to your Colab notebook,\n",
    "2. the .ipynb file, and\n",
    "3. a pdf of the executed notebook on Canvas.\n",
    "\n",
    "To generate a pdf of the notebook, click File > Print > Save as PDF."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Kernel PCA\n",
    "\n",
    "Principal component analysis (PCA) is a classical method for reducing the dimensionality (number of attributes) in the data by projecting the data from its original high-dimensional space into a lower-dimensional space. The conventional formulation of PCA is limited to finding a linear projection of the data, so if the original data are not linearly separable then the PCA-projected data also will not be. Kernel PCA is a simple modification of PCA that uses kernel functions to project data into a higher-dimensional space where it may become linearly separable and compute PCA in the higher-dimensional space, using special kernel functions to make this computation feasible.\n",
    "\n",
    "In this section, we will apply Kernel PCA to the same image dataset from Lab 11 and compare the results to linear PCA."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the dataset\n",
    "\n",
    "We will use a preprocessed subset of the “Labeled Faces in the Wild” (LFW) dataset, which you can read more about [here](http://vis-www.cs.umass.edu/lfw/)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import fetch_lfw_people\n",
    "\n",
    "lfw_people = fetch_lfw_people(min_faces_per_person=70)\n",
    "\n",
    "# data attribute gives the data matrix with the image dimension flattened\n",
    "X = lfw_people.data\n",
    "print('Num samples: {}'.format(X.shape[0]))\n",
    "print('Num features: {}'.format(X.shape[1]))\n",
    "\n",
    "# images attribute gives the unflattened image dimension\n",
    "print('Image dimensions: {} x {}'.format(lfw_people.images.shape[1], lfw_people.images.shape[2]))\n",
    "\n",
    "# the label to predict is the id of the person\n",
    "y = lfw_people.target\n",
    "# target_names attribute tells us the name of the person associated with each id\n",
    "target_names = lfw_people.target_names\n",
    "n_classes = target_names.shape[0]\n",
    "print('Num classes: {}'.format(n_classes))\n",
    "print('Class names:', target_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The dataset has 1,288 images of the faces of 7 different people. The code below prints the number of samples from each class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(n_classes):\n",
    "    print('Number of instances in class {} ({}): {}'.format(i,\n",
    "                                                            target_names[i],\n",
    "                                                            y[y==i].shape[0]\n",
    "                                                           ))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To get an idea of what is in our dataset, we visualize a random face from each class below. (Note: You can run this cell many times to see different random examples.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fig, axes = plt.subplots(ncols=n_classes, figsize=(13,6))\n",
    "\n",
    "for i in range(n_classes):\n",
    "    rand_ind = np.random.randint(0, y[y==i].shape[0])\n",
    "    axes[i].imshow(lfw_people.images[y==i][rand_ind], cmap='gray')\n",
    "    axes[i].axis('off')\n",
    "    axes[i].set_title(target_names[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we will split the data into training and test subsets, using 30\\% of the data for testing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.3, random_state=42\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we standardize the data so that the mean of all attributes is 0 using the StandardScaler() object in scikit-learn to standardize the data. We fit the scaler to the training data and apply it to both the training and test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Kernel PCA\n",
    "\n",
    "Kernel PCA uses one of several choices of kernel functions to transform the data into a higher-dimensinoal space and then compute the principal components (eigenvectors) of the data in the high-D space. We then use these principal components to transform the data into a new set of features that maximizes variance in the dataset. \n",
    "\n",
    "The KernelPCA class in scikit-learn gives four options for kernel functions (the same functions available for SVM): 'poly', 'rbf', 'sigmoid', and 'cosine'. In the code below, we implement KernelPCA using 10 principal components and the sigmoid kernel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import KernelPCA\n",
    "\n",
    "n_components = 10\n",
    "\n",
    "kpca = KernelPCA(n_components=n_components, kernel='sigmoid', fit_inverse_transform=True).fit(X_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can use our PCA model (i.e., the principal component vectors found in our data) to transform our dataset into the new reduced-dimensional space. This is done in the below code using the `transform()` function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_kpca = kpca.transform(X_train)\n",
    "X_test_kpca = kpca.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SVM classifier with Kernel PCA\n",
    "\n",
    "Now that we've reduced the dimensionality of our dataset from 2914 to 10, we can use these new features as our inputs for classification. In this example, we'll use a Support Vector Machine (SVM) classifier. In the cell below, train an SVM with `C=10000` and `kernel='rbf'`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "\n",
    "clf = SVC(C=10, kernel='rbf')\n",
    "clf = clf.fit(X_train_kpca, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the cell below, use the trained model to make predictions for the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = clf.predict(X_test_kpca)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next cell shows how we can use the `classification_report()` function in sklearn to print several metrics computed for the test set. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "print(classification_report(y_test, y_pred, target_names=target_names))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also use the `ConfusionMatrixDisplay` object to visualize the confusion matrix for the test set predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import ConfusionMatrixDisplay\n",
    "\n",
    "ConfusionMatrixDisplay.from_estimator(\n",
    "    clf, X_test_kpca, y_test, display_labels=target_names, xticks_rotation=\"vertical\"\n",
    ")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 1: What is the difference between the covariance matrix and the confusion matrix? What are the dimensions of each in terms of the number of attributes (m) and the number of classes (c)? How are each used here?**\n",
    "\n",
    "**Answer:**\n",
    "\n",
    "YOUR ANSWER HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data reconstruction\n",
    "\n",
    "We can reconstruct the original input images by multiplying the encoded data in the principal subspace by the principal component vectors. This reverse transformation is called the *inverse transform*. The code below reconstructs the original data using the KernelPCA `inverse_transform()` function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_recon_kpca = kpca.inverse_transform(X_train_kpca)\n",
    "test_recon_kpca = kpca.inverse_transform(X_test_kpca)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a plot to visualize the original image and reconstructed image for the first 5 images in the test set. Plot the original images on the first row and the reconstructions on the second row. Print the class name as the title for each original image and turn off the axis labels/tickmarks (as in the earlier face visualization from this lab)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(ncols=5, nrows=2, figsize=(10,5))\n",
    "n_images = 5\n",
    "\n",
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In Lab 11, we used linear PCA to reduce the data dimensionality and use the transformed data as the input to SVM as we did in Lab 12 with KernelPCA. However, in Lab 11 we did not reconstruct the original data from the principal subspace as we did above with KernelPCA. \n",
    "\n",
    "In the cell(s) below, fit a new linear PCA model with 10 principal components (same as was done in Lab 11). Then, plot the above visualization again, but this time add a third row for the same images reconstructed using linear PCA."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Autoencoder neural network\n",
    "\n",
    "An autoencoder is a type of neural network in which the outputs are the same as the inputs. In other words, the goal of the network is to reconstruct the original input image by minimizing the mean squared error loss function. The autoencoder consists of two main components: an encoder network that maps the input data to a low dimensional representation $z$ and a decoder network that maps $z$ back to the original dimension. \n",
    "\n",
    "In the code below, we implement a simple autoencoder network using dense (feed-forward) layers and train it using our LFW faces dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "seed = 256\n",
    "tf.keras.utils.set_random_seed(seed)\n",
    "\n",
    "import keras\n",
    "from keras import layers\n",
    "\n",
    "# This is the size of our encoded representations\n",
    "encoding_dim = 32  \n",
    "\n",
    "# This is our input image\n",
    "input_img = keras.Input(shape=(X_train.shape[1],))\n",
    "# \"encoded\" is the encoded representation of the input\n",
    "encoded = layers.Dense(128, activation='relu')(input_img)\n",
    "encoded = layers.Dense(64, activation='relu')(encoded)\n",
    "encoded = layers.Dense(encoding_dim, activation='relu')(encoded)\n",
    "\n",
    "# \"decoded\" is the lossy reconstruction of the input\n",
    "decoded = layers.Dense(64, activation='relu')(encoded)\n",
    "decoded = layers.Dense(128, activation='relu')(decoded)\n",
    "decoded = layers.Dense(X_train.shape[1], activation='sigmoid')(decoded)\n",
    "\n",
    "# This model maps an input to its reconstruction\n",
    "autoencoder = keras.Model(input_img, decoded)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In addition to the full autoencoder model, we can construct the encoder and decoder models separately. Here we will construct the encoder model so that we can use it to reduce the data dimensionality without having to also reconstruct the data (which is done by `autoencoder`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This model maps an input to its encoded representation\n",
    "encoder = keras.Model(input_img, encoded)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we compile the model. We'll use the Adam optimizer and mean squared error loss."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "autoencoder.compile(optimizer='adam', loss='mse')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we train our model. Below we train for 100 epochs using a batch size of 32. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "autoencoder.fit(x=X_train, y=X_train,\n",
    "                epochs=100,\n",
    "                batch_size=32,\n",
    "                shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 2: In the code above, why did we set x and y both equal to `X_train`?**\n",
    "\n",
    "**Answer:**\n",
    "\n",
    "YOUR ANSWER HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we have our trained autoencoder for which the input is an image and the output is the reconstruction. Next we use our trained autoencoder to reconstruct the test images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_recon_ae = autoencoder.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the cell below, visualize the same 5 as we did for KernelPCA and linear PCA. You can copy the same code as the previous code block used for visualization and add a fourth row for the autoencoder reconstructions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 3: The reconstructions by the autoencoder do not look as accurate as the reconstructions by the PCA and KernelPCA models. This does not mean that linear or kernel PCA is inherently better than an autoencoder for reducing the dimensionality of this dataset---it is probable that if we spent time tuning all the hyperparameters of the autoencoder, we would find a model that has a better solution. However, there are many more hyperparameters to tune in the autoencoder compared to the PCA models. List at least three hyperparameters that could be optimized for the autoencoder.**\n",
    "\n",
    "**Answer:**\n",
    "\n",
    "YOUR ANSWER HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 4: The autoencoder we implemented here used feed-forward/dense layers. Another way to improve the autoencoder reconstruction could be to use a different type of layer. What other type of layer might give better performance (e.g., convolutional, recurrent) and why?**\n",
    "\n",
    "**Answer:**\n",
    "\n",
    "YOUR ANSWER HERE"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
